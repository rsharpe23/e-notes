ПРО МАТРИЦЫ

Матрицы в основном используются для взаимосвязи между двумя координатами.

Определитель матрицы - это её число (результирующее).

Транспонирование матрицы - это операция, при которой строки становятся 
столбцами, а столбцы - строками.

Преобразования матриц бывают линейными и аффинными.

Линейные преобразования - это повороты и масшабирования. Они сохраняют состояние 
и могут приминяться в любой последовательности. Например если применить масштабирован,
а затем поворот, то результат будет таким же, как если бы сначала применить 
поворот, а затем масштабирование.

Преобразование считается линейным, если оно сохраняет базовые операции 
сложения и умножения на скаляр.

Аффинное преобразование - это линейное преобразование, за которым следует сдвиг.

Матрицы 3x3 используются для линейных преобразований и они не содержат сдвига.
Любое преобразование которое выполняется через матричное умножение не может содержать
сдвига. Для выполнения преобразований со сдвигом, нужно использовать матрицы 4x4.

Если объект необходимо двигать или поворачивать, то нужно преобразовать его вершины
(из локальных?) в экранные/мировые координаты с пом. матрицы модели (ModelView).

Чтобы преобразовать вершину, нужно умножить её на матрицу модели (с пом. векторного
произведения): Vf = Mv * V, где Mv - матрица модели 4х4, а V - вектор вершины. 
Каждая вершина должна определяться как: [x, y, z, w]. 

Матрица проекции преобразов. вершины относительно их расстояния к зрителю: 
Vp = P * V, где P - матрица проекции 4х4, V - вектор.

Параметры при установке матрицы проекции:

* fieldOfView - поле зрения; чем больше значение, тем больше объектов 
  будет охвачено на сцене;

* Near, Far - ближняя и дальняя плоскости для создания области отсечения;

Чтобы правильно отобразить вершину объекта на экране, нужно матрицу модели умножить 
на вектор вершины (перевести вектор в глобальное пространство), затем матрицу
проекции умножить на вектор вершины в глобальном пространстве.
...
vec4 gVertexPos = mvMatrix * vertexPos;
gl_Position = pMatrix * gVertexPos;

Чтобы получить матрицу модели, нужно умножить матрицу вида на мировую матрицу.
Мировая матрица - это матрица, содержащая трансформации объекта.

----------------------

ОСНОВЫ 3D-ГРАФИКИ

Модель в 3D-игре называется мешом. Каждая грань меша называется полигоном. 
Полигон состоит из 3х и более вершин. Каждая вершина обозначается местоположением 
на экране. Местоположение определяется с помощью векторов.

Каждой вершине, которая определяется, даётся числовая метка; например, вершина 0
помечается нулём, вершина 1 - единицей и т.д. Эти метки называются индексами.

Индексы информируют WebGL о том, как соединять вершины, чтобы 
сформировался полигон или поверхность.

Чтобы получить наиболее гладкую поверхность, с минимальным кол-вом полигонов, нужно
использовать полигоны с наименьшим кол-во сторон, т.е. треугольники. Если вместо
треугольников использовать квадраты, то их придется задать намного больше. Также 
у треугольников 2 из 3х сторон общие, тогда как у квадратов 2 из 4х.

------------------------

КОНВЕЙЕР ОТРИСОВКИ (RENDERING PIPELINE)

Старые видеокарты не позволяли напрямую изменять или манипулировать вершинами, 
но имели встроенный ф-ционал для их поворорота или масштабирования.

Современный конвейер отрисовки даёт полную гибкость в изменении вершины 
и отрисовки объектов с пом. шейдеров.

Этапы конвейера отрисовки (стр. 19):

  JavaScript > Вершинный шейдер > Сборка примитивов и Растеризация 
                                                V
  Фреймбуфер < Pre-fragment шейдер < Фрагментный шейдер

Графические ускоритель (graphics accelerator) - это аппаратное обеспечение 
(hardware), предназначенное для рисования графики. 

Он имеет область памяти для хранения содержимого отображения. Каждый видимый пиксель
представлен несколькими байтами памяти (display memory); Эта память обновляется
определенное кол-во раз в секунду для обеспечения отсутствия мерцания.

Граический ускоритель также предоставляет внеэкранную память (offscreen momory),
которая используется только для хранения данных.

Распределение памяти отображения и внеэкранной памяти управляется оконной системой.

Область графической памяти, которая изменяется в результате рендеринга называется
фреймбуфером. Фреймбуфер по умолчан. предоставляется оконной системой.

Если необходимо выполнить рендеринг в текстуру, то нужно создавать 
закадровый (внеэкранный) фреймбуфер.

--------------------

ОСНОВЫ WEBGL

Буферный объект предоставляет методы для загрузки атрибутов на видеокарту. Он даёт
существенный прирост производительности при рендеринге, поскольку его данные находятся
в видеопамяти: const bufferObj = gl.createBuffer();

Буферных объектов может быть много. Метод bindBuffer() вызывается, чтобы сообщить, 
на каком из объектов буфера будут работать последующие операции (WebGL).

Буферный объект может быть вершинным (VBO - Vertex Buffer Object) и индексным (IBO).

Тип ELEMENT_ARRAY_BUFFER используется только для хранения индексов. Для остальных
данных, используется ARRAY_BUFFER (позиции, цвета, нормали и т.п.).

Метод bufferData() выделяет память для буферного объекта. Третий параметр указывает,
как его использовать. Обычно передается значение STATIC_DRAW.

Все значения 3го параметра:

* STATIC_DRAW - данные объекта указаны приложением один раз и используются
  много раз для рисования примитивов;

* DYNAMIC_DRAW - данные объекта указаны приложением неоднократно и используются 
  много раз для рисования примитивов; используется для анимации отдельных вершин;

* STREAM_DRAW - данные объекта указаны приложением один раз и используются 
  всего несколько раз для рисования примитивов;

Программа WebGL разделена на два компонента; управляющий код JS и шейдеры.
Управляющий код выполняется на CPU, а шейдеры на GPU. Поскольку управляющий код
связывает данные с памятью GPU, он доступен для обработки в шейдере.

Вершинный шейдер - это программируемый модуль, который работает с входящими значениями
вершин и связанными с ними данными (позиции вершин, их цвета, нормали и пр.).

Обычно в нём выполняются след. операции:
* вершинные преобразования;
* преобразования нормалей и нормализация;
* генерация текстурных координат и их преобразования;
* применение материала и освещения;

Данные, которые передаются в вершинный шейдер:
* атрибуты - поэтапные данные вершин, поставляемые из вершинных буферов.
* униформы - константные данные сразу для всего шейдера; вершинный и фрагментный 
  шейдеры имеют общее глобальное пространство для униформ.

gl_Position - это varying-переменная, которая объявляется автоматически.

После того, как вершинный шейдер отработает с атрибутами вершин, следующая фаза - это
сборка примитивов (Primitive Assembly). На этой фазе, если примитив лежит частично 
за пределами усеченной пирамиды вида (frustum view) то он обрезается, а если он 
вне её пределов, то полностью отсекается. 

После этого идёт фаза растеризации. На этой фазе все примитивы преобразуются в
двумерные фрагменты, также называемые пикселями. Эти фрагменты затем 
обрабатываются фрагментным шейдером.

Во фрагментном шейдере выполняются след.:
* операции над интерполированными значениями;
* доступ к текстурам;
* применение текстур;
* сумма цветов;
* туман;

Данные, которые передаются во фрагментный шейдер:

* varying-переменные - данные из вершинного шейдера, генерируемые при 
  растеризации для каждого фрагмента (с помощью интерполяции).

* униформы - константные данные сразу для всего шейдера.

* семплеры - это особые типы, используемые фрагментным шейдером, 
  которые представляют текстуры.

Атрибуты, объявленные в шейдере, инициализируются в основном управляющем коде.
Чтобы их инициализировать, необходимо получить на них ссылки через метод
getAttribLocation(). Он как бы запрашивает местоположение атрибута.

Атрибутами могут быть только вещественные числа, а также векторы 
или матрицы (с вещественными числами).

Чтобы получить ссылку на униформу, используется метод getUniformLocation(). 
А метод uniform*() загружает данные в униформу.

Метод vertexAttribPointer() сопоставляет текущий активный буфер с атрибутом шейдера.
Его 4й параметр (norm) это индикатор, указывающий, используются ли невещественные
данные, которые должны быть нормализованы, перед конвертацией во float.

Метод drawArrays() эффективен, когда нужно отрисовать простую геометрию.
Для сложной геометрии используется метод drawElements(). Он использует IBO и метод
drawArrays(), который в свою очередь использует VBO для чтения данных.

Этапы построения WebGL-приложений:
* создать контекст WebGL;
* загрузить, скомпилировать и линкануть шейдеры;
* инициализировать буферные объекты;
* применить преобразования и соединить буферные объект с атрибутами;
* вызвать drawArrays() или drawElements();

Управляющий код отлаживается по обычному, через console.log() и интструменты отладчика.
Отладка шейдеров происходит с помощью браузерного плагина - WebGL Inspector.

------------------------

НОРМАЛИ И ОСВЕЩЕНИЕ

Точность для типа float в вершинном шейдере может быть низкой, а во фрагметном -
высокой, поскольку вершинам, в основном, передаются конкертные значения, а пикселям - 
промежуточные (интерполируемые), требующие более точного рассчета.

Нормали также необходимо преобразовывать в мировое пространство; поскольку после
поворота или сдвига объекта они, как и вершины, поменяют свои значения. 

Чтобы преобразовать нормаль, нужно сначала найти транспонирование 
обратной ModelView-матрицы:
...
const nMatrix = mat3.create();
mat4.toInverseMat3(mvMatrix, nMatrix);  -->  Матрица нормалей - это обратная 
mat3.transpose(nMatrix);                     ModelView-матрица

gl.uniformMatrix3fv(u_NMatrix, false, nMatrix);

Затем, в шейдере, умножить сырую нормаль на транспонированную матрицу:
const tNormal = u_NMatrix * a_Normal;

Типы источников света:
* Направленный свет (directional lights) - солнечный свет;
* Точечный свет (point lights) - свет лампы;
* Прожектор (spotlights) - фонарь;

Окрущающее освещение (Ambient lighting) создает равномерный свет. Вычисляется по
формуле: I = Ia Ka, где Ia - интенсивность фонового света, Ka - коэффициент фонового
отражения объектов, от 0.0 до 1.0 для каждого RGB-компонента. Его свойства:

* генерируется направленным источником света;
* имитирует свет, который отражается от разных поверхностей;
* его интенсивность не меняется от положения полигонов в пространстве;
* позиция зрителя не важна;

Диффузное (рассеянное) отражение (Diffuse reflection) - это отражение света от
поверхности, при котором падающий луч отражается под многими углами. 

Вычисляется по формуле: I = Ip Kd (N'.L'), где Ip - интенсивность точечного света, 
Kd - коэффициент диффузного отражения объектов, от 0.0 до 1.0 для каждого RGB-компонен.
N' - нормализованная нормаль поверхности/вершины, L' нормализованное направление
источника света, точка - это скалярное произведение 2х векторов.

Свойства диффузного отражения:

* яркость полигона зависит от теты - угла между нормалью поверхности (N) 
  и направлением источника света (L);

* позиция зрителя зависит от того, используется ли направленный свет или точечный;

Материал - это описание поверхности объекта. Свойства материала описывают то, как он
отражает фоновый и диффузный свет, а также характеристики зеркального блеска.

Фоновое и диффузное отражения работают вместе, чтобы определить воспринимаемый цвет
объекта и обычно задаются одинаковым цветом. Например, если материал отражает только
зеленый цвет, фонового и диффузного света, то находясь в сцене с белым светом, 
объект будет зелёным. Но если свет станет синим, то объект почернеет, 
т.к. материал не отражает синего.

Зеркальное отражение задаёт блики на объектах, делая их блестящими. Оно определяется
двумя свойствами: цветом блика и общим блеском материала.

------------------

МОДЕЛИ ОСВЕЩЕНИЯ/ОТРАЖЕНИЯ

Алгоритмы, используемые для рассчета направления, интенсивности и цвета 
отраженного света называются моделями отражения.

Модели отражения используют цветовые компоненты (фоновый, диффузный и зеркальный)
источника света, а также материал объекта для вычисления цвета фрагмента.

Рендеринг изображений с реалистичной моделью отражения называется BRDF 
(Bidirectional Reflectance Distribution Functions). Распространенные модели BRDF:

* Модель Ламберта - самая простая модель; используется для рендеринга объектов 
  с диффузным материалом и рассеянным светом.

* Модель Фонга - модель, подобная пластиковой зеркальности; но она не работает
  когда угол между вектором обзора (V) и вектором отражения (R) больше 90 градусов.

* Модель Блинна-Фонга - модифицир. модель Фонга, которая допускает определенные
  интерполяции и снижает вычислительные затраты; используется для рендеринга 
  объектов с зеркальным материалом.

* Модель Торренса-Спарроу - общая модель, кот. представляет поверхности как
  распределения идеальных зекральных микрограней;

* Модель Кука-Торренса - модель Торренса-Спарроу, кот. учитывает длину волны 
  и, следовательно, изменение цвета.

* Анизитропная модель Уорда - модель зеркальных микрограней с 
  эллиптической ф-цией распределения по Гауссу.

В играх, в основном, используются модели Ламберта и Блинна-Фонга, 
т.к. они требуют наименьших вычислений.

------------------

МОДЕЛИ ЗАТЕНЕНИЯ/ИНТЕРПОЛЯЦИИ

Модель затенения определяет, будем ли мы вычислять освещение только для вершин или 
для каждого пикселя грани. Если вычислять освещение для вершин, то значения пикселей
между вершинами линейно интерполируются. При этом вычисления придётся делать 
в вершинном шейдере.

Вершинный шейдер выполняется для каждой вершины. Следовательно, это дорого. Посему
предпочтительнее это делать попиксельно, во фрагментном шейдере (возможно тут имеется
ввиду, что расчет освещения, отдельно для каждого пикселя, дешевле интерполяции).

Наиболее распространенные модели затенения:

* Плоское затенение (Flat shading) - используется для высокоскоростного рендеринга;

* Затенение Гуро (Gouraud shading) - сила и слабость этого затенения заключается 
  в его интерполяции; если полигон охватывает больше пикселей на экранне чем число
  собсвтенных вершин, то значения интерполируемых цветов из дорогостоящих рассчетов
  освещения в вершинах менее загружают процессор, чем выполнение расчета для каждого
  пикселя; однако зеркальные блики могут отображаться неправильно;

* Затенение Фонга (Phong shading) - работает лучше, чем затенение Гуро, когда
  применяется к модели отражения с небольшими зеркальными бликами, например к Фонгу.

Затенение Гуро для модели отражения Ламберта на стр. 75. 
Расчет освещения выполняется в вершинном шейдере.

Затенение Гуро для модели отражения Блинна-Фонга на стр. 80.
Расчет освещения выполняется в вершинном шейдере.

Затенение Фонга для модели отражения Блинна-Фонга на стр. 82.
Основной расчет освещения выполняется во фграгментном шейдере. 
Вершинный шейдер только подготавливает некоторые переменные.

------------------

НЕСКОЛЬКИХ ОБЪКТОВ И ИСТОЧНИКОВ СВЕТА

Каждая 3D-модель может быть представлена классом Geometry. Объект Geometry должен
содержать примерно такие данные: вершины, нормали, UV-координаты, материалы, индексы.

В последствии все эти данные должны передаваться соответсвующим буферам:
...
gl.bindBuffer(gl.ARRAY_BUFFER, vbo);
gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(geometry.vertices), ...);

gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, ibo);
gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, new Uint16Array(geometry.indices), ...);

gl.bindBuffer(gl.ARRAY_BUFFER, tbo);
gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(geometry.uvs[materialIndex]), ...);

Класс Face представляет собой полигон 3D-модели.
Пример реализации классов Geometry и Face на стр. 86.

Класс StageObject содержит информацию для рендеринга геометрии на сцене. Он
инициализирует объект Geometry, а также буферные объекты и дефолтный материал для
Geometry. Также он сожержит местоположение и поворот объекта относительно сцены.

Класс Stage содержит массив объектов сцены - StageObject, а также 
инициализированный контекст WebGL (в переменной gl).

Пример реализации классов Stage и StageObject на стр. 92.

Чтобы отобразить несколько объектов на сцене, в главном коде нужно последовательно
проинициализировать все StageObject, предварительно связав их со Stage, 
и вызывать метод drawScene() для каждого объекта сцены. 
...
initGL(canvas)
initShaders();
initScene();

const stage = new Stage(gl);

const stageObject1 = new StageObject();
stage.addModel(stageObject1);
drawObject();

const stageObject2 = new StageObject();
stage.addModel(stageObject2);
drawObject();

Если для рендеринга всех объектов используется одна пара шейдеров, то униформы
материала и света, для каждого из объектов, должны устанавливаться 
внутри метода drawObject().

WebGL не выполняет рендеринг нескольких буферов в один момент времени. При загрузке
нескольких объектов у нас будет несколько буферов. Чтобы отрендерить все эти 
буферы, придется сначала активировать каждый из них по очереди.

Чтобы получить информацию об активном буфере и состоянии конвейера рендеринга, нужно
использовать следующие методы (использ. для ARRAY_BUFFER и ELEMENT_ARRAY_BUFFER):
...
gl.getParameter(gl.ARRAY_BUFFER_BINDING);  -->  получить ссылку на привязанный 
                                                на данный момент VBO

gl.getBufferParameter(gl.ARRAY_BUFFER, gl.BUFFER_SIZE);  -->  размер получ. буфера
gl.getBufferParameter(gl.ARRAY_BUFFER, gl.BUFFER_STATUS);  -->  статус получ. буфера

gl.isBuffer(...);

Перед тем, как трансформировать объект, нужно сохранить исходную матрицу mvMatrix 
в матричном стеке, а после рендерига объекта - восстановить её. Иначе преобразования
объектов будут относительно друг-друга, а не относительно сцены.
...
const mStack = [];

function pushMatrix() {
  const temp = mat4.create();
  mat4.copy(temp, mvMatrix);
  mStack.push(temp);
}

function popMatrix() {
  if (mStack.length > 0) {
    mvMatrix = mStack.pop();
  }  
}

function drawObject(index) {
  pushMatrix();
    mat4.translate(mvMatrix, mvMatrix, stage.stageObjects[index].location);
    mat4.rotateX(mvMatrix, mvMatrix, stage.stageObjects[index].rotationX);
    // Активация буферов и вызов drawElements(...)
  popMatrix();
}

У WebGL ограничено кол-во создаваемых униформ. Если привысить лимит, то будет ошибка
компиляции шейдеров. Чтобы запросить разрешенно кол-во униформ, использ. вызовы:
...
gl.getParameter(gl.MAX_VERTEX_UNIFORM_VECTORS);
gl.getParameter(gl.MAX_FRAGMENT_UNIFORM_VECTORS);

Это ограничение не позволяет реализовать множество источников освещения. 
Но чтобы его обойти, можно использовать массивы: 
...
const int LIGHTS_COUNT = 2;
uniform vec3 u_LightPositions[LIGHTS_COUNT];
varying vec3 u_LightRays[LIGHTS_COUNT];

for (int i = 0; i < LIGHTS_COUNT; i++) {
  vec4 lightPos = mvMatrix * vec4(u_LightPositions[i], 1.0);
  u_LightRays[i] = vertexPos - lightPos.xyz;
}

gl.uniform3fv(u_LightPositions, [4, 10, -10, -4, 10, -10]);  -->  массив 2х векторов

Окружающий (ambient) цвет не нужно рассчитывать в шейдерах, поскольку он не зависит 
от расстояния и ориентации объекта. Вместо этого можно суммировать его от всех
источников света и передать эту сумму в шейдер.

Пример реализации множественного освещения (с точечным светом) на стр. 110.
Отражение по Блинн-Фонгу. Затениние по Фонгу.

Для реализации источника света используется класс Light.js. Он хранит его цвета,
направление и позицию. Для реализации всего освещения в целом использ. класс Lights.

------------------

ТЕКСТУРИРОВАНИЕ

Существует 3 типа текстур: 2D-текстуры, 3D-текстуры и Cubemap-текстуры 
(текстуры кубической карты). 

3D-текстуры редко используюся в играх. С пом. них в основном создают объемные эффекты,
такие как реалистичный туман или световые лучи. 

2D-текстура - это двумерный массив данных, обычно изображение формата .jpg или .png.
Тексели представлены в форматах: gl.RGB, gl.RGBA, gl.LUMINANCE или gl.ALPHA.
Тексели индексируется текстурными координатами.

Концепция мапинга, когда вершина полигона сопоставляется с определенной текстурной
координатой, называется -  Texture Mapping или UV Mapping.

Каждая текстурная координата представлена парой (s, t) или (u, v) и называется
текселем. U/S - представляет горизонтальную ось, а V/T - вертикальную ось.

Чтобы определить оптимальный цвет пикселя, применяются фильтры. Самый простой алгоритм
фильтрации выбирает цвет из ближайшего пикселя (интерполяция ближайших соседей). 

Поскольку объект, к которому применяется текстура, может находится на произвольном
расстоянии и в произвольной ориентации от камеры, один пиксель на экране может не
соответствовать напрямую одному текселю. 

Например, если переместить объект ближе к камере, размер текселей станет больше, 
чем размер пикселей на экране и их придется масштабировать. Процесс масштаблирования
текстуры называется Texture Magnification.

Если отодвинуть объект от камеры, то каждый тексель, наоборот, станет меньше пикселя 
и поэтому один пиксель может покрывать сразу несколько текселей. В этом случае
соответсвующий цвет будет подобран на основе покрытых текселей путем 
минификации текстуры - Texture Minification.

Метод pixelStorei() устанавливает режимы хранения пикселей для readPixels() 
и раскпаковывает текстуры с пом. texImage2D() и texSubImage2D().

Метод bindTexture() подобен bindBuffer(). Он делает указаную текстуру текущей для
дальнейших операций, таких как: texImage2D(), texParameteri() и др.

Метод texImage2D() основной. Он загружает текстуру в память GPU:
* target - цель; либо это TEXTURE_2D, либо одна из граней кубической карты;
* level - указывает какой mipmap-уровень загружать;
* internalFormat - внутренний формат хранения текстур: RGBA, LUMINANCE, ALPHA и др;
* format - формат данных пикселей: GL_RED, GL_RGBA, GL_BRGA и др;
* type - тип входящих данных пикселей: UNSIGNED_BYTE, UNSIGNED_SHORT_4_4_4_4 и др;
* pixels - содержит актуальные данные пикселей для изображения;

Метод texParameteri() устанавливает параметр для текущей текстуры:
* target - цель; например: GL_TEXTURE_1D, GL_TEXTURE_2D, GL_TEXTURE_CUBE_MAP и др;
* pname - имя параметра текстуры: GL_TEXTURE_MAG_FILTER, GL_TEXTURE_MIN_FILTER и др;
* param - значение для параметра текстуры;

WebGL может обрабатывать до 32х текстур при отрисовке примитива 
через drawArrays() или drawElements().

Метод activeTexture() активирует в GPU один из 32х текстурных юнитов.
Его параметр принимает спец. индексы, от TEXTURE0 до TEXTURE31 (константы чисел). 

Затем, к юниту привязывается сама текстура, через bindTexture().
После этого можно передать текстуру в семплер, ссылаясь на неё через индекс.
...
gl.activeTexture(gl.TEXTURE0);   -->  TEXTURE0 совпадает с 0 в uniform1i()
gl.bindTexture(gl.TEXTURE_2D, texture);
gl.uniform1i(u_Sampler, 0);

Из-за ограничения в 32 текстуры, обычно для каждого примитива создают одну большую
текстуру, которая размещает в себе все необходимые текстуры поменьше 
(кол-во маленьких текстур может превышать 32).

Подход, когда для одного примитива задается несколько текстур, называется
мультитекстурированием (стр. 158). Оно используется когда нужны какие-то эффекты.

Мультитекстурирование реализуется путём смешивания нескольких текстур между собой, 
для получения усредненных значений (цвета) текселей.

Сэмплер содержит ссылку на текстуру. Задаётся он типом: sample1D/2D/3D. Переменную
сэмплера нельзя инициализировать каким-то значением. Её можно только объявить. 

В ф-цию передаётся только как входной параметр (с ключевым словом in):
void myFunction(in sampler2d myTexture) { }

Процесс получения данных из текстуры называется сэмплингом. Ф-ция texture*()
возвращает тексель текстуры, по заданным координатам. Размерность координат зависит 
от размерности сэплера, например для sampler1D координаты представлены типом float, 
а для sampler2D - типом vec2.

Ф-ция textureOffset() добавляет тексельное смещение к текстурным координатам.
Это полезно при сэмплинге коллекции изображений, в одну текстуру.

Пример текстурирования куба на стр. 124.
Пример загрузки модели с текстурами на стр. 148.

Для сочетания текстурирования с освещением, нужно итоговый цвет, полученный через
освещение, умножить на цвет текселя из текстуры:
...
gl_FragColor = vec4(iColor, 1.0) * texture2D(u_Sampler, vTexCoord);

Важно знать, что в этом случае, при рассчете освещения не должен использоваться
диффузный цвет материала, т.е. пропускаем meterialDiffuseColor (стр. 208).
...
iColor = u_AmbientColor * materialAmbientColor + uDirColor * dirLightWeighting +
  u_SpecularColor * materialSpecualColor * specular;

Mipmap'ы - это оптимизированная коллекция изображений главной текстуры. Они
используется для увеличения скорости рендеринга и уменьшения артефактов сглаживания.

Средство визуализации (рендерер) переключается на подходящее mipmap-изображение 
в зависимости от расстояния до объекта. Mipmapping позволяет свести к минимуму
появление различных артефактов при рендеринге.

Mipmap'ы генерируются автоматически с пом. метода: gl.generateMipmap().
При этом можно загружать серию изображений вручную.
...
gl.bindTexture(gl.TEXTURE_2D, texture);
gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, img);
gl.texImage2D(gl.TEXTURE_2D, 1, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, img256);
gl.texImage2D(gl.TEXTURE_2D, 2, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, img128);
gl.texImage2D(gl.TEXTURE_2D, 3, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, img64);

В примере выше загружается несколько mipmap-изображений для одного и того же 
буферного объекта с разными уровнями детализации (LOD).

Методы фильтрации текстур:

Интерполяция ближайших соседей - самый простой и быстрый метод фильтрации. В качестве
цвета пикселя он просто использует цвет текселя, ближайшего к центру пикселя. Однако
рендеринг текстур будет не очень хорошим. Появляется много артефактов, таких как
блочность при увеличении и сглаживание/мерцание при уменьшении.
...
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);

Линейная интерполяция (билинейная фильтрация) - метод, в котором выбираются четыре,
ближайших к центру пикселя, текселя, цвета которых комбинируются по средневзвешанному
значению их растояния. Это устраняет блочность, наблюдаемую при увеличении.
...
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);

Ближайшие соседи с mipmapping'ом - сначала выбирается наиболее подходящий уровень
mipmap, а затем тексель, ближайший к центру пикселя. Значительно уменьшает сглаживание
и мерцание, но не помогает с блочностью.
...
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST_MIPMAP_NEAREST);

Билинейная фильтрация с mipmapping'ом - четыре, ближайших к центру пикселя, текселей
выбираются на ближайшем mipmap-уровне. Цвета текселей комбинируются по средневзвешанн.
значению их расстояния. Устраняет блочность, наблюдаемую при увеличении. Таким образом,
вместо резкого изменения цвета теперь происходить плавный градиент изменеия цвета 
от одного текселя к другому.
...
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR_MIPMAP_NEAREST);

Трилинейная фильтрация - сначала выполняет поиск текстуры, а затем применяет билинейн.
фильтрацию (1) или фильтрацию ближайших соседей (2) на два ближайших mipmap-уровня.
После этого линейно интерполирует полученные значения. Это решает распространенную
проблему, возникающую в билинейно отфильтрованных mipmap-изображениях. Очень заметно
изменение качества, когда рендерер переключается с одного mipmap-уровня на другой. 
...
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR_MIPMAP_LINEAR);  (1)
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST_MIPMAP_LINEAR); (2)

Mipmapping и соответствующие ему методы фильтрации можно применять только к POT-
изображениям (высота и ширина равна степени двойки: 64х64, 256х128). К изображениям,
отличным от POT, можно применять только билинейную фильтрацию и ближайших соседей.

Кубические карты (cubemaps) - это текстуры, кот. используются в играх для аппроксимац.
отражения окружающей среды на поверхности модели. Это может быть, например, 
skylight-освещение или скайбоксы.

Кубическая карта состоит из шести двумерных изображений, соответсвующих граням куба.
Координаты текстуры определяются с помощью вектора направления. 

Вектор направления имеет след. компоненты: s, t, p. Он исходит из центра куба 
и указывает на текслель грани (стр. 157).

Пример реализации кубической карты (мультитекстурирование):
...
сonst cubeTbo = gl.createTexture();
gl.bindTexture(gl.TEXTURE_CUBE_MAP, cubeTbo);

gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MIN_FILTER, gl.LINEAR);

gl.texImage2D(gl.TEXTURE_CUBE_MAP_POSITIVE_X,  
              0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image1);

gl.texImage2D(gl.TEXTURE_CUBE_MAP_NEGATIVE_X, 
              0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image2);

gl.texImage2D(gl.TEXTURE_CUBE_MAP_POSITIVE_Y,  
              0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image3);

gl.texImage2D(gl.TEXTURE_CUBE_MAP_NEGATIVE_Y, 
              0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image4);

gl.texImage2D(gl.TEXTURE_CUBE_MAP_POSITIVE_Z, 
              0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image5);

gl.texImage2D(gl.TEXTURE_CUBE_MAP_NEGATIVE_Z, 
              0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image6);

gl.activeTexture(gl.TEXTURE0);  
gl.bindTexture(gl.TEXTURE_2D, texture);
gl.uniform1i(u_Sampler, 0); 

gl.activeTexture(gl.TEXTURE1);
gl.bindTexture(gl.TEXTURE_2D, cubeTexture);
gl.uniform1i(u_CubeSampler, 1);

Применение кубической карты во фрагментном шейдере:
...
gl_FragColor = vec4(iColor, 1.0) * texture2D(u_Sampler, v_TexCoord) 
  * textureCube(u_CubeSampler, tNormal);  -->  смешиваем тексели TEXTURE0 и TEXTURE1

------------------

РАБОТА С КАМЕРОЙ

Для поворота камеры, нужно повернуть вектор: взгляда, верха или вправо.
Вращение вокруг вектора взгляда называется Roll. Вращение вокруг верха - Yaw. 
Вращение вокруг вектора вправо - Pitch (cм. связанная система координат самолета).
Вращение по этим векторам/осям задается через углы Эйлера.

Но такое вращение имеет недостаток. При повороте объекта, его оси поворачиваются 
вместе с ним. Если одну из осей повернуть на 90 градусов, то она станет параллельной
другой оси. В этом случае обе оси будут вращаться в одном и том же направлении. 
Это проблема называется - шарнирный замок (gimbal lock).

Чтобы избежать этого, используют кватернионы. Кватернион состоит из 4х компонентов: 
x, y, z, w. Компоненты xyz - это ось вращения, а w - величина поворота:
...
0, 1, 0, 45  -->  поворот вокруг Y на 45 градусов.

Помимо этого, вращение с использованием кватернионов происходит намного 
быстрее, чем при использовании матрицы поворота.

Кватернион можно получить из матрицы вращения и также получить матрицу 
из кватерниона: quat.fromMat3(); mat3.fromQuat(); 

Видимый объем камеры имеет форму усеченной пирамиды (frustum - пиримида со срезанным
кончиком). Объекты, находящиеся вне видимого объема, исключаются из рендеринга.
Видимый объем определяется ближней и дальней плоскостями пирамиды.

Угол обзора (field of view) - это угол между камерой и осью Y. Изменение угла приведет
к расширению или сжатию пирамиды, т.е. к уменьшение или увеличению объектов. 
Обычно задается в приделах от 45 до 60 градусов.

Соотношение сторон (aspect ratio) - это величина, определяющая форму пирамиды
(квадратная или прямоугольная пирамида). Определяется путем деления ширины основания 
на высоту основания. От этого зависит, будут ли объекты вытянутыми или зауженными.

В 3D-играх обычно используются камеры 3х типов: 
* свободная (free) - камера от первого лица, кот. перемещается в любом направлении;
* целевая (target) - камера от третьего лица, кот. следует за своей целью;
* орбитальная (orbit) - целевая камера, кот. вращается вокруг цели;

Класс Camera является базовым для всех камер (стр. 173).
Класс FreeCamera предоставляет ф-ционал свободной камеры (стр. 177).
Класс OrbitCamera предоставляет ф-ционал орбитальной камеры (стр. 191).

Реализация ф-ций вращения свободной камеры (через кватернионы):
...
const pitch = angle => rotateOnAxis(left, angle);
const yaw = angle => rotateOnAxis(up, angle);
const roll = angle => rotateOnAxis(dir, angle);

// Так задается поворот, относильно локальных координат
// Векторы dir, up, left вычисляются также, как в алгоритме  
// вычисления матрицы вида (стр. 179).

function rotateOnAxis(axis, angle) {
  const q = quat.create();
  quat.setAxisAngle(q, axis, angle);

  vec3.transformQuat(dir, dir, q);
  vec3.normalize(dir, dir);

  vec3.transformQuat(left, left, q);
  vec3.normalize(left, left);

  vec3.transformQuat(up, up, q);
  vec3.normalize(up, up);
}

Ф-ция moveForward() перемещает камеру в направлении взгляда, 
на расстояние distance:
...
function moveForward(distance) {
  const x = pos[0] - distance * dir[0];
  const y = pos[1] - distance * dir[1];
  const z = pos[2] - distance * dir[2];
  pos = vec3.fromValues(x, y, z);
}

Ф-ция update() заставляет целевую камеру перемещаться/вращаться 
вместе с игровой моделью:
...
function update(timeStep) {
  if (vec3.squaredLength(linVel) > 0.0) {
    vec3.scale(vel, vel, timeStep);
    vec3.add(pos, vel, pos);
  }

  if (vec3.squaredLength(angVel) > 0.0) {
    pitch(angVel[0] * timeStep);
    yaw(angVel[1] * timeStep);
    roll(angVel[2] * timeStep);
  }
}

Чтобу установить камеру, используется матричный метод lookAt(). 
Он, по сути, и генерирует матрицу вида:
...
const viewMat = mat4.create();
const lookAtPos = vec3.create();
vec3.add(lookAtPos, pos, dir);
mat4.lookAt(viewMat, pos, lookAtPos, up);

Первый параметр (выходной) - это матрица вида. Второй параметр - позиция камеры. 
Третий - позиция взгляда. Четвёртый - вектор вверх (0, 1, 0).

Позиция взгляда (то, куда смотрит камера) вычисляется путём сложения 
позиции камеры с её направлением.

Алгоритм вычисления матрицы вида в lookAt():
...
Vector3 zAxis = normal(lookAtPos - pos);   -->  вектор взгляда
Vector3 xAxis = normal(cross(up, zAxis));  -->  вектор вправо
Vector3 yAxis = cross(zAxis, xAxis);       -->  вектор вверх

Matrix4 orientationMat = {       -->  матрица поворота?
  xAxis.x, yAxis.x, zAxis.x, 0,
  xAxis.y, yAxis.y, zAxis.y, 0,
  xAxis.z, yAxis.z, zAxis.z, 0,
  0, 0, 0, 1
};

Matrix4 translationMat = {
  1, 0, 0, 0
  0, 1, 0, 0,
  0, 0, 1, 0,
  -pos.x, -pos.y, -pos.z, 1
};

viewMat = translationMat * orientationMat;

Орбитальная камера - это та, что вращается вокруг цели и постоянно смотрит на неё.
Также, её можно понимать как камеру, которая движется по поверхности сферы.

Следовательно, её местоположение определяется тремя параметрами: азимутом, 
высотой (elevation) и радиусом (стр. 190).

Азимут - это угол горизонтального поворота, а высота - вертикального.

В играх, азимут можно заменить термином рыскание (yaw), высоту - тангажом (pitch),
а радиус - расстоянием. Кроме того, рыскание и тангаж, в отличии от азимута 
и высоты, используют дополнительные углы.

Простейшая реализация вращения орбитальной камеры:
...
const q = quat.create();
quat.fromEuler(q, 10, 45, 0);

const pos = vec3.fromValues(0, 0, -distance);
vec3.transformQuat(pos, pos, rot);

------------------

УПРАВЛЕНИЕ

При нажатии клавиши можно вращать камеру, умножая Пи на некий коэффициент:
camera.roll(-Math.PI * 0.025);

Чтобы управлять мышью, нужно рассчитывать угол поворота на основе расстояния,
пройденного при перетаскивании.

Класс KeyBoardInteractor задаёт управление камерой, через обработку клавишь (стр. 185).
Класс MouseInteractor задаёт управление камерой с помощью мыши (стр. 187).

------------------

РАЗНОЕ

Кол-во источников света и выбор алгоритма затенения влияют на производительность.
Нужно стараться чтобы кол-во источников света было минимальным, подменяя их 
запеканием теней и лайтмапами. А еще нужно избегать зеркальных отражений, 
т.к. они сильно нагружают GPU.

materialDiffuseColor - одно из названий для свойства материала.
lamberdTerm - член Ламберта: max(dot(normal, -lightDir), 0.0);
specular - член Блинна: pow(specAngle, 16.0);

Обозначение суффиксов у некоторых методов:
...
funcName[1234][fi][v]() - означает ф-цию/метод с 1,2,3,4-параметрами типа float 
или int; если в конце стоит символ v, то вместо чисел нужно передавать 
вектор с 1,2,3,4-размерностью (т.е. массив).

Обзор форматов .obj и .mtl на стр. 55 и 131.
Конвертация файлов в JSON-файл на стр. 57.

Отношения между различными данными (вершин, нормалей, uv-координат) 
закодированы в массиве Faces.

Количество uv-координат должно быть равно кол-ву вершин. Если эти количества не
совпадают, то нужно создать избыточные координаты, чтобы их уровнять.

Модели объектов, текстуры, шейдеры и пр. обычно подгружаются через Ajax.

Метод requestAnimationFrame() вызывается только тогда, когда вкладка браузера находится
в фокусе. Это экономит ресурсы GPU. С помощью него можно получить цикл рендеринга,
который будет выполнятся настолько быстро, насколько позволяют браузеры.

Что такое materialFile? (как-то связанно с текстурами и mapDiffuse).
Это свойство StageObject, которое содержит текстуру объекта.

